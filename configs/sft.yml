model: EleutherAI/gpt-neo-125M

dataset:
  loader: sft
  name: databricks/databricks-dolly-15k
  subset_size: 5000
  max_seq_length: 512
  clean: true 

training:
  epochs: 3
  batch_size: 4
  learning_rate: 5e-5
  gradient_accumulation: 2
  logging_steps: 50

output:
  model_dir: models/sft_model
